#!/usr/bin/env bash

# Unoffical Bash "strict mode"
# http://redsymbol.net/articles/unofficial-bash-strict-mode/
set -euo pipefail
IFS=$'\t\n' # Stricter IFS settings
#ORIGINAL_IFS=$IFS

usage() {
    cat <<EOF | awk 'NR==1 && match($0, /^ +/){n=RLENGTH} {print substr($0, n+1)}'
    Usage: website_downloader [url] [destination_dir] [options]

    Options:

      --localize - sets options needed for a complete local copy of the static
      website with localized links
      --overwrite - overwrite any existing local files when downloading the website
      --rate-limit - rate limit requests
      --only-subdirectory - limit downloads to the subdirectory specified in the URL
      --path-regex regex - only download paths matching regex

    Examples:

      Download only the blog/ section of stratus3d.com and localize all links and download css/js
      for a fully working local copy:

      $ website_downloader http://stratus3d.com/blog/ stratus3d_posts --only-subdirectory --localize
EOF
}

error_exit() {
  printf "Error: %s\\n\\n" "$@"
  usage
  exit 1
}

get_value() {
  raw_flag=$1
  first=${1#*'='}
  second=$2

  # If the raw flag contains an equals sign and the value after it (first) is
  # not null return first, otherwise return the next argument (second)
  if [[ "$raw_flag" == *=* ]] && [ -n "$first" ]; then
    echo "$first"
  else
    if [[ "$second" == -* ]]; then
      echo "$second"
    else
      echo "$second"
    fi
  fi
}

get_shift_count() {
  if [[ "$1" == *=* ]]; then
    echo "1"
  else
    echo "2"
  fi
}

#cookies_file="$HOME/cookies.txt"
#-e robots=off \
# Use cookies from file. Usefully when dealing with site behind a login page
#--load-cookies=$cookies_file

url=${1:-}
directory=${2:-}

if [ -z "$url" ]; then
  error_exit "URL must be provided as first argument"
fi

if [ -z "$directory" ]; then
  error_exit "Output directory must be provided as second argument"
fi

domain="$(echo "$url" | awk -F[/:] '{print $4}')"

# Base command: follow links and download the whole site
command_array=("$url" --recursive --mirror '--domains='"$domain")

shift 2

while :; do
    case ${1:-} in
        -h|-\?|--help)
            usage
            exit
            ;;
        -r|--path-regex|--path-regex=*)
            path_regex=$(get_value "$1" "${2:-}")
            shift $(get_shift_count "$1")

            # Add path regex flags
            #
            # --accept-regex - Accept all pages with a path matching the regex
            # specified
            command_array+=(--accept-regex "$path_regex")
            ;;
        -n|--no-overwrite)
            shift

            # Add flags to tell wget not to overwrite existing files
            #
            # --no-clobber - Don't overwrite existing files when downloading
            command_array+=(--no-clobber)
            ;;
        -s|--rate-limit|--rate-limit=*)
            rate=$(get_value "$1" "${2:-}")
            shift $(get_shift_count "$1")

            # Add flags to tell wget to rate limit requests
            command_array+=(--wait="$rate" '--limit-rate=10K')
            ;;
        -l|--fully-local)
            shift

            # Add flags to tell wget to format pages for local viewing
            # (with localized links and downloaded assets)
            #
            # --page-requisites - Download CSS and other assets
            # --html-extension - Save files with the .html extension
            # --convert-links - Change URLs in links so they work offline
            # --restrict-file-names=windows - modify filenames so they will work in Windows
            # --adjust-extension - Save HTML and CSS with the proper extensions
            command_array+=(--page-requisites --html-extension
            --convert-links '--restrict-file-names=windows' --mirror --adjust-extension)
            ;;
        -d|--only-subdirectory)
            shift

            # Only download pages from a specific subdirectory
            #
            # --no-parent - Don't follow links outside the directory
            command_array+=(--no-parent "$url")
            ;;
        --)
            shift
            break
            ;;
        *)
            if [ -z "${1:-}" ]; then
                break
            else
                echo "Unknown option ${1:-}"
                error_exit
            fi
    esac
done

set -x
wget "${command_array[@]}"
set +x
